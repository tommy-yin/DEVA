import os
import glob
import json
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
from scipy.ndimage import gaussian_filter1d
import argparse
import re
import csv


def parse_ground_truth(gt_file):
    """
    è§£æ ground truth æ–‡ä»¶ï¼Œè¿”å›å­—å…¸ï¼Œé”®ä¸ºè§†é¢‘æ–‡ä»¶å¤¹åç§°ï¼Œå€¼ä¸ºåŒ…å«æ€»å¸§æ•°å’Œå¼‚å¸¸åŒºé—´çš„å­—å…¸
    æ–‡ä»¶æ ¼å¼ï¼švideo_name total_frames start1 end1 [start2 end2 ...]
    ä¾‹å¦‚ï¼š
      01_Accident_004.mp4 190 53 118
      Normal_012.mp4 70 -1 -1
    """
    gt_ranges = {}
    if not os.path.exists(gt_file):
        print(f"Ground truth æ–‡ä»¶ {gt_file} ä¸å­˜åœ¨ï¼")
        return gt_ranges
    
    with open(gt_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            
            parts = line.split()
            if len(parts) < 4:
                continue
            
            video_name = parts[0]  # e.g., "01_Accident_004.mp4"
            total_frames = int(parts[1])
            
            # å»æ‰.mp4åç¼€ä½œä¸ºé”®
            video_key = os.path.splitext(video_name)[0]  # e.g., "01_Accident_004"
            
            anomaly_regions = []
            # è§£æå¼‚å¸¸åŒºé—´ï¼Œæˆå¯¹è¯»å–
            for i in range(2, len(parts), 2):
                if i + 1 < len(parts):
                    start = int(parts[i])
                    end = int(parts[i + 1])
                    # -1 -1 è¡¨ç¤ºæ­£å¸¸è§†é¢‘
                    if start != -1 and end != -1:
                        anomaly_regions.append((start, end))
            
            gt_ranges[video_key] = {
                'total_frames': total_frames,
                'anomaly_regions': anomaly_regions
            }
    
    return gt_ranges


def extract_frame_number(frame_name):
    """
    ä»å¸§æ–‡ä»¶åä¸­æå–å¸§å·
    ä¾‹å¦‚: "frame_0080.jpg" -> 80
    """
    match = re.search(r'(\d+)', frame_name)
    if match:
        return int(match.group(1))
    return 0


def load_crad_results(crad_file):
    """
    ä»CRADç»“æœæ–‡ä»¶ä¸­åŠ è½½å¼‚å¸¸åˆ†æ•°
    è¿”å›æ ¼å¼: {video_folder: {frame_number: anomaly_score}}
    """
    with open(crad_file, 'r', encoding='utf-8') as f:
        crad_data = json.load(f)
    
    results = {}
    for video_folder, data in crad_data.items():
        if isinstance(data, dict) and any(key.endswith('.jpg') or key.endswith('.png') for key in data.keys()):
            results[video_folder] = {}
            for frame_name, frame_data in data.items():
                if frame_name.endswith(('.jpg', '.png')) and isinstance(frame_data, dict):
                    if 'anomaly_score' in frame_data:
                        frame_number = extract_frame_number(frame_name)
                        results[video_folder][frame_number] = frame_data['anomaly_score']
    
    return results


def load_weight_scores(video_name, scores_dir="/root/my_VAD/demo_module2_sampling/result_sample_5"):
    """
    åŠ è½½æŒ‡å®šè§†é¢‘çš„contextualå’Œsemanticåˆ†æ•°
    
    å‚æ•°:
        video_name: è§†é¢‘åç§°ï¼ˆå¦‚ "031"ï¼‰
        scores_dir: scoresæ–‡ä»¶ç›®å½•
    
    è¿”å›:
        frame_names, context_scores, semantic_scores
    """
    scores_file = os.path.join(scores_dir, f"{video_name}.mp4_scores.json")
    
    if not os.path.exists(scores_file):
        print(f"æœªæ‰¾åˆ°æƒé‡åˆ†æ•°æ–‡ä»¶: {scores_file}")
        return None, None, None
    
    try:
        with open(scores_file, 'r', encoding='utf-8') as f:
            scores_data = json.load(f)
        
        frame_names = scores_data.get('frame_names', [])
        context_scores = scores_data.get('context_scores_norm', [])
        semantic_scores = scores_data.get('semantic_scores_norm', [])
        
        # print(f"æˆåŠŸåŠ è½½æƒé‡åˆ†æ•°æ–‡ä»¶: {scores_file}")
        # print(f"  - å¸§æ•°: {len(frame_names)}")
        # print(f"  - Contextualåˆ†æ•°: {len(context_scores)}")
        # print(f"  - Semanticåˆ†æ•°: {len(semantic_scores)}")
        
        return frame_names, context_scores, semantic_scores
        
    except Exception as e:
        print(f"åŠ è½½æƒé‡åˆ†æ•°æ–‡ä»¶å¤±è´¥: {e}")
        return None, None, None


def interpolate_scores_to_full_video(frame_scores, total_frames, normalize=True):
    """
    å°†é‡‡æ ·å¸§çš„å¼‚å¸¸åˆ†æ•°çº¿æ€§æ’å€¼åˆ°å®Œæ•´è§†é¢‘çš„æ‰€æœ‰å¸§
    
    å‚æ•°:
        frame_scores: {frame_number: anomaly_score}
        total_frames: è§†é¢‘æ€»å¸§æ•°ï¼ˆä»ground truthè·å–ï¼‰
        normalize: æ˜¯å¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œé»˜è®¤ä¸ºTrue
    
    è¿”å›:
        full_indices: å®Œæ•´å¸§ç´¢å¼•
        interpolated_scores: æ’å€¼åçš„å¼‚å¸¸åˆ†æ•°
    """
    if not frame_scores:
        print(f"æ²¡æœ‰æ‰¾åˆ°å¼‚å¸¸åˆ†æ•°æ•°æ®")
        return None, None
    
    # æå–å¹¶æ’åºé‡‡æ ·å¸§
    sample_indices = sorted(frame_scores.keys())
    sample_scores = [frame_scores[idx] for idx in sample_indices]
    
    # åˆ›å»ºå®Œæ•´å¸§ç´¢å¼•
    full_indices = np.arange(0, total_frames)
    
    # çº¿æ€§æ’å€¼
    interpolated_scores = np.interp(full_indices, sample_indices, sample_scores)
    
    # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦å½’ä¸€åŒ–åˆ°0-1åŒºé—´
    if normalize:
        min_score = np.min(interpolated_scores)
        max_score = np.max(interpolated_scores)
        if max_score > min_score:
            interpolated_scores = (interpolated_scores - min_score) / (max_score - min_score)
    
    # é«˜æ–¯å¹³æ»‘
    smoothed_scores = gaussian_filter1d(interpolated_scores, sigma=5)
    
    return full_indices, smoothed_scores


def interpolate_scores_to_full_video_weighted(frame_scores, total_frames, video_name, normalize=True, scores_dir="/root/my_VAD/demo_module2_sampling/result_sample_5", distance_weight_factor=2.0, context_weight_factor=1.0, semantic_weight_factor=1.5):
    """
    ä½¿ç”¨contextualå’Œsemanticåˆ†æ•°ä½œä¸ºæƒé‡ï¼Œå°†é‡‡æ ·å¸§çš„å¼‚å¸¸åˆ†æ•°è¡¥å…¨åˆ°å®Œæ•´è§†é¢‘çš„æ‰€æœ‰å¸§
    
    å‚æ•°:
        frame_scores: {frame_number: anomaly_score} é‡‡æ ·å¸§çš„å¼‚å¸¸åˆ†æ•°
        total_frames: è§†é¢‘æ€»å¸§æ•°ï¼ˆä»ground truthè·å–ï¼‰
        video_name: è§†é¢‘åç§°ï¼ˆç”¨äºåŠ è½½æƒé‡åˆ†æ•°ï¼‰
        normalize: æ˜¯å¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œé»˜è®¤ä¸ºTrue
        scores_dir: æƒé‡åˆ†æ•°æ–‡ä»¶ç›®å½•
        distance_weight_factor: è·ç¦»æƒé‡å› å­ï¼Œé»˜è®¤ä¸º2.0
        context_weight_factor: contextualæƒé‡å› å­ï¼Œé»˜è®¤ä¸º1.0
        semantic_weight_factor: semanticæƒé‡å› å­ï¼Œé»˜è®¤ä¸º1.5
    
    è¿”å›:
        full_indices: å®Œæ•´å¸§ç´¢å¼•
        interpolated_scores: è¡¥å…¨åçš„å¼‚å¸¸åˆ†æ•°
    """
    if not frame_scores:
        print(f"æ²¡æœ‰æ‰¾åˆ°å¼‚å¸¸åˆ†æ•°æ•°æ®")
        return None, None
    
    # åŠ è½½æƒé‡åˆ†æ•°
    frame_names, context_scores, semantic_scores = load_weight_scores(video_name, scores_dir)
    
    if frame_names is None or context_scores is None or semantic_scores is None:
        print(f"æƒé‡åˆ†æ•°åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°çº¿æ€§æ’å€¼æ–¹æ³•")
        return interpolate_scores_to_full_video(frame_scores, total_frames, normalize)
    
    # ç¡®ä¿æƒé‡åˆ†æ•°çš„é•¿åº¦ä¸è§†é¢‘å¸§æ•°åŒ¹é…
    if len(context_scores) == total_frames - 1 and len(semantic_scores) == total_frames - 1:
        # å¦‚æœæƒé‡åˆ†æ•°æ¯”è§†é¢‘å¸§æ•°å°‘1ï¼ˆé€šå¸¸æƒ…å†µï¼‰ï¼Œåœ¨æœ«å°¾æ·»åŠ æœ€åä¸€ä¸ªå€¼
        context_scores.append(context_scores[-1])
        semantic_scores.append(semantic_scores[-1])
        print(f"æƒé‡åˆ†æ•°é•¿åº¦è°ƒæ•´ï¼šæ‰©å±•åˆ° {len(context_scores)} å¸§")
    elif len(context_scores) != total_frames or len(semantic_scores) != total_frames:
        print(f"æƒé‡åˆ†æ•°é•¿åº¦ä¸åŒ¹é…ï¼šcontext={len(context_scores)}, semantic={len(semantic_scores)}, video_frames={total_frames}")
        print(f"å›é€€åˆ°çº¿æ€§æ’å€¼æ–¹æ³•")
        return interpolate_scores_to_full_video(frame_scores, total_frames, normalize)
    
    # æå–å¹¶æ’åºé‡‡æ ·å¸§
    sample_indices = sorted(frame_scores.keys())
    sample_scores = [frame_scores[idx] for idx in sample_indices]
    
    # print(f"å¼€å§‹åŸºäºæƒé‡çš„åˆ†æ•°è¡¥å…¨...")
    # print(f"  - é‡‡æ ·å¸§æ•°: {len(sample_indices)}")
    # print(f"  - æ€»å¸§æ•°: {total_frames}")
    # print(f"  - é‡‡æ ·å¸§ç´¢å¼•: {sample_indices}")
    
    # åˆ›å»ºå®Œæ•´å¸§ç´¢å¼•
    full_indices = np.arange(0, total_frames)
    interpolated_scores = np.zeros(total_frames)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿è®¡ç®—
    context_scores = np.array(context_scores)
    semantic_scores = np.array(semantic_scores)
    sample_indices = np.array(sample_indices)
    sample_scores = np.array(sample_scores)
    
    # å¯¹æ¯ä¸€å¸§è®¡ç®—å¼‚å¸¸åˆ†æ•°
    for frame_idx in range(total_frames):
        if frame_idx in frame_scores:
            # å¦‚æœæ˜¯é‡‡æ ·å¸§ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åˆ†æ•°
            interpolated_scores[frame_idx] = frame_scores[frame_idx]
        else:
            # å¯¹äºéé‡‡æ ·å¸§ï¼Œä½¿ç”¨æƒé‡æ–¹æ³•è®¡ç®—åˆ†æ•°
            weights = np.zeros(len(sample_indices))
            
            for i, sample_idx in enumerate(sample_indices):
                # 1. è·ç¦»æƒé‡ï¼šè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§
                distance = abs(frame_idx - sample_idx) + 1  # é¿å…é™¤é›¶
                distance_weight = 1.0 / (distance ** distance_weight_factor)
                
                # 2. Contextualæƒé‡ï¼šè€ƒè™‘å½“å‰å¸§ä¸é‡‡æ ·å¸§ä¹‹é—´çš„contextualç›¸ä¼¼æ€§
                # å–å½“å‰å¸§å’Œé‡‡æ ·å¸§ä¹‹é—´è·¯å¾„ä¸Šçš„contextualåˆ†æ•°çš„å¹³å‡å€¼
                start_idx = min(frame_idx, sample_idx)
                end_idx = max(frame_idx, sample_idx)
                if start_idx == end_idx:
                    context_weight = context_scores[frame_idx]
                else:
                    context_weight = np.mean(context_scores[start_idx:end_idx+1])
                
                # 3. Semanticæƒé‡ï¼šå½“å‰å¸§çš„semanticåˆ†æ•°
                semantic_weight = semantic_scores[frame_idx]
                
                # 4. é‡‡æ ·å¸§çš„semanticåˆ†æ•°ä¹Ÿè€ƒè™‘è¿›æ¥
                sample_semantic_weight = semantic_scores[sample_idx]
                
                # ç»¼åˆæƒé‡è®¡ç®—
                # è·ç¦»æƒé‡ Ã— contextualç›¸ä¼¼åº¦ Ã— å½“å‰å¸§semanticæƒé‡ Ã— é‡‡æ ·å¸§semanticæƒé‡
                combined_weight = (distance_weight * 
                                 (1 + context_weight * context_weight_factor) * 
                                 (1 + semantic_weight * semantic_weight_factor * sample_semantic_weight))
                
                weights[i] = combined_weight
            
            # å½’ä¸€åŒ–æƒé‡
            if np.sum(weights) > 0:
                weights = weights / np.sum(weights)
                # åŠ æƒå¹³å‡è®¡ç®—è¯¥å¸§çš„å¼‚å¸¸åˆ†æ•°
                interpolated_scores[frame_idx] = np.sum(weights * sample_scores)
            else:
                # å¦‚æœæƒé‡å…¨ä¸º0ï¼Œä½¿ç”¨æœ€è¿‘é‚»æ–¹æ³•
                nearest_idx = np.argmin(np.abs(sample_indices - frame_idx))
                interpolated_scores[frame_idx] = sample_scores[nearest_idx]
    
    print(f"æƒé‡è¡¥å…¨å®Œæˆ")
    # print(f"  - è¡¥å…¨ååˆ†æ•°èŒƒå›´: [{np.min(interpolated_scores):.4f}, {np.max(interpolated_scores):.4f}]")
    
    # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦å½’ä¸€åŒ–åˆ°0-1åŒºé—´
    if normalize:
        min_score = np.min(interpolated_scores)
        max_score = np.max(interpolated_scores)
        if max_score > min_score:
            interpolated_scores = (interpolated_scores - min_score) / (max_score - min_score)
            # print(f"  - å½’ä¸€åŒ–ååˆ†æ•°èŒƒå›´: [{np.min(interpolated_scores):.4f}, {np.max(interpolated_scores):.4f}]")
    
    # é«˜æ–¯å¹³æ»‘
    smoothed_scores = gaussian_filter1d(interpolated_scores, sigma=5)
    print(f"  - é«˜æ–¯å¹³æ»‘å®Œæˆï¼Œsigma=5")
    
    return full_indices, smoothed_scores


def plot_anomaly_curve(full_indices, smoothed_scores, video_name, gt_ranges, output_dir, original_frame_scores=None, video_metrics=None):
    """
    ç»˜åˆ¶å¼‚å¸¸åˆ†æ•°æ›²çº¿å›¾ï¼Œæ ¹æ® ground truth åŒºé—´ç”¨çº¢è‰²é€æ˜èƒŒæ™¯æ ‡ç¤º
    
    å‚æ•°:
        original_frame_scores: åŸå§‹é‡‡æ ·å¸§çš„å¼‚å¸¸åˆ†æ•° {frame_number: anomaly_score}
        video_metrics: è§†é¢‘æŒ‡æ ‡å­—å…¸ï¼ŒåŒ…å«AUROCå’ŒAUPRç­‰ä¿¡æ¯
    """
    plt.figure(figsize=(12, 6))
    
    # ç»˜åˆ¶æ’å€¼åçš„å¹³æ»‘æ›²çº¿
    plt.plot(full_indices, smoothed_scores, 'b-', linewidth=1.5, label='Interpolated Anomaly Score', alpha=0.8)
    
    # ç»˜åˆ¶åŸå§‹é‡‡æ ·ç‚¹
    if original_frame_scores:
        sample_indices = list(original_frame_scores.keys())
        sample_scores = list(original_frame_scores.values())
        plt.scatter(sample_indices, sample_scores, color='red', s=30, zorder=5, 
                   label='Original Sample Points', alpha=0.9)
    
    plt.xlabel('Frame Index')
    plt.ylabel('Anomaly Score')
    
    # æ„å»ºåŒ…å«æŒ‡æ ‡çš„æ ‡é¢˜
    if video_metrics and video_metrics['status'] == 'success':
        title = f'Anomaly Detection Results for Video {video_name}\nAUROC: {video_metrics["auroc"]:.4f} | AUPR: {video_metrics["aupr"]:.4f} | Anomaly Frames: {video_metrics["anomaly_frames"]}/{video_metrics["total_frames"]} ({video_metrics["anomaly_ratio"]*100:.1f}%)'
    else:
        # å¯¹äºæ— æ³•è®¡ç®—æŒ‡æ ‡çš„è§†é¢‘ï¼Œä½¿ç”¨ç®€å•çš„æ ‡é¢˜
        title = f'Anomaly Detection Results for Video {video_name}'
    
    plt.title(title, fontsize=11)
    plt.ylim(0, 1)
    plt.grid(True, alpha=0.3)
    
    # æ ‡æ³¨å¼‚å¸¸åŒºé—´
    if video_name in gt_ranges and gt_ranges[video_name]['anomaly_regions']:
        for i, (start, end) in enumerate(gt_ranges[video_name]['anomaly_regions']):
            plt.axvspan(start, end, color='red', alpha=0.2, 
                       label='Ground Truth Anomaly' if i == 0 else "")
    
    plt.legend()
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    os.makedirs(output_dir, exist_ok=True)
    save_path = os.path.join(output_dir, f"anomaly_curve_{video_name}.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"å¼‚å¸¸æ›²çº¿å·²ä¿å­˜: {save_path}")


def compute_metrics(crad_results, gt_file, output_dir, normalize=True, use_weighted_interpolation=True, scores_dir="/root/my_VAD/demo_module2_sampling/result_sample_5", distance_weight_factor=2.0, context_weight_factor=1.0, semantic_weight_factor=1.5):
    """
    è®¡ç®—å¼‚å¸¸æ£€æµ‹æŒ‡æ ‡å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    
    å‚æ•°:
        crad_results: CRADç»“æœæ•°æ®
        gt_file: ground truthæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        normalize: æ˜¯å¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œé»˜è®¤ä¸ºTrue
        use_weighted_interpolation: æ˜¯å¦ä½¿ç”¨æƒé‡è¡¥å…¨æ–¹æ³•ï¼Œé»˜è®¤ä¸ºTrue
        scores_dir: æƒé‡åˆ†æ•°æ–‡ä»¶ç›®å½•
        distance_weight_factor: è·ç¦»æƒé‡å› å­ï¼Œé»˜è®¤ä¸º2.0
        context_weight_factor: contextualæƒé‡å› å­ï¼Œé»˜è®¤ä¸º1.0
        semantic_weight_factor: semanticæƒé‡å› å­ï¼Œé»˜è®¤ä¸º1.5
    
    è¿”å›:
        auroc, aupr: è¯„ä¼°æŒ‡æ ‡
    """
    gt_dict = parse_ground_truth(gt_file)
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"Ground truth åŒ…å« {len(gt_dict)} ä¸ªè§†é¢‘:")
    gt_keys = list(gt_dict.keys())[:5]  # æ˜¾ç¤ºå‰5ä¸ª
    print(f"Ground truth ç¤ºä¾‹é”®: {gt_keys}")
    
    crad_keys = list(crad_results.keys())[:5]  # æ˜¾ç¤ºå‰5ä¸ª
    crad_names = [os.path.basename(key) for key in crad_keys]
    crad_names_no_ext = [os.path.splitext(name)[0] for name in crad_names]
    print(f"CRAD results ç¤ºä¾‹é”®: {crad_keys}")
    print(f"CRAD basename: {crad_names}")
    print(f"CRAD basename (no ext): {crad_names_no_ext}")
    print()
    
    y_true_all = []
    y_scores_all = []
    
    # æ·»åŠ åªåŒ…å«å¼‚å¸¸è§†é¢‘çš„æ•°æ®æ”¶é›†
    y_true_anomaly_only = []
    y_scores_anomaly_only = []
    
    total_videos = 0
    processed_videos = 0
    total_sample_frames = 0
    
    # ç»Ÿè®¡å¼‚å¸¸è§†é¢‘æ•°é‡
    anomaly_videos_processed = 0
    
    # å­˜å‚¨æ¯ä¸ªè§†é¢‘çš„è¯¦ç»†æŒ‡æ ‡
    video_metrics = {}
    
    print(f"ä½¿ç”¨è¡¥å…¨æ–¹æ³•: {'æƒé‡è¡¥å…¨' if use_weighted_interpolation else 'çº¿æ€§æ’å€¼'}")
    
    for video_folder, frame_scores in crad_results.items():
        video_name_full = os.path.basename(video_folder)  # å¯èƒ½åŒ…å«.mp4åç¼€
        video_name = os.path.splitext(video_name_full)[0]  # å»æ‰.mp4åç¼€ï¼Œä¸gt_dictçš„é”®æ ¼å¼ä¸€è‡´
        total_videos += 1
        
        if video_name not in gt_dict:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°è§†é¢‘ {video_name_full} çš„ground truthä¿¡æ¯")
            continue
        
        # ä»ground truthè·å–æ€»å¸§æ•°
        total_frames = gt_dict[video_name]['total_frames']
        
        # é€‰æ‹©è¡¥å…¨æ–¹æ³•
        if use_weighted_interpolation:
            full_indices, smoothed_scores = interpolate_scores_to_full_video_weighted(
                frame_scores, total_frames, video_name, normalize, scores_dir, distance_weight_factor, context_weight_factor, semantic_weight_factor)
        else:
            full_indices, smoothed_scores = interpolate_scores_to_full_video(
                frame_scores, total_frames, normalize)
        
        if full_indices is None or smoothed_scores is None:
            print(f"è·³è¿‡è§†é¢‘ {video_name_full}ï¼ˆè¡¥å…¨å¤±è´¥ï¼‰")
            continue
        
        # è®¡ç®—æ ‡ç­¾
        segments = gt_dict[video_name]['anomaly_regions']
        y_true = np.zeros(len(full_indices))
        for start, end in segments:
            y_true[start:end+1] = 1
        
        # è®¡ç®—å•ä¸ªè§†é¢‘çš„æŒ‡æ ‡
        video_auroc = 0.0
        video_aupr = 0.0
        video_status = "success"
        video_error_msg = ""
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®è®¡ç®—æŒ‡æ ‡
            unique_labels = np.unique(y_true)
            if len(unique_labels) > 1:  # æ—¢æœ‰æ­£å¸¸å¸§åˆæœ‰å¼‚å¸¸å¸§
                video_auroc = roc_auc_score(y_true, smoothed_scores)
                precision, recall, _ = precision_recall_curve(y_true, smoothed_scores)
                video_aupr = auc(recall, precision)
                print(f"âœ… è§†é¢‘ {video_name_full}: AUROC={video_auroc:.4f}, AUPR={video_aupr:.4f}")
            else:
                # å…¨éƒ¨æ˜¯æ­£å¸¸å¸§æˆ–å…¨éƒ¨æ˜¯å¼‚å¸¸å¸§
                video_status = "skipped"
                if unique_labels[0] == 0:
                    video_error_msg = "å…¨éƒ¨ä¸ºæ­£å¸¸å¸§ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡"
                else:
                    video_error_msg = "å…¨éƒ¨ä¸ºå¼‚å¸¸å¸§ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡"
                print(f"âš ï¸  è§†é¢‘ {video_name_full}: {video_error_msg}")
        
        except Exception as e:
            video_status = "error"
            video_error_msg = str(e)
            print(f"âŒ è®¡ç®—è§†é¢‘ {video_name_full} æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
        
        # æ„å»ºå½“å‰è§†é¢‘çš„æŒ‡æ ‡å­—å…¸
        current_video_metrics = {
            'auroc': video_auroc,
            'aupr': video_aupr,
            'status': video_status,
            'error_message': video_error_msg,
            'total_frames': len(full_indices),
            'sample_frames': len(frame_scores),
            'anomaly_frames': int(np.sum(y_true)),
            'anomaly_ratio': float(np.sum(y_true) / len(y_true)),
            'anomaly_segments': len(segments),
            'score_range': {
                'min': float(np.min(smoothed_scores)),
                'max': float(np.max(smoothed_scores)),
                'mean': float(np.mean(smoothed_scores)),
                'std': float(np.std(smoothed_scores))
            }
        }
        
        # ç»˜åˆ¶å¼‚å¸¸æ›²çº¿ï¼Œä¼ é€’è®¡ç®—å¥½çš„æŒ‡æ ‡
        plot_anomaly_curve(full_indices, smoothed_scores, video_name, gt_dict, output_dir, 
                          original_frame_scores=frame_scores, video_metrics=current_video_metrics)
        
        # ä¿å­˜è§†é¢‘çº§åˆ«çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä½¿ç”¨video_nameä½œä¸ºé”®ï¼Œä¸gt_dictä¿æŒä¸€è‡´ï¼‰
        video_metrics[video_name] = current_video_metrics
        
        # æ”¶é›†æ•°æ®ç”¨äºæ•´ä½“è¯„ä¼°
        y_true_all.extend(y_true)
        y_scores_all.extend(smoothed_scores)
        
        # æ·»åŠ åªåŒ…å«å¼‚å¸¸è§†é¢‘çš„æ•°æ®æ”¶é›†ï¼ˆè§†é¢‘åç§°ä¸­æ²¡æœ‰"Normal"çš„ä¸ºå¼‚å¸¸è§†é¢‘ï¼‰
        if "Normal" not in video_name:
            y_true_anomaly_only.extend(y_true)
            y_scores_anomaly_only.extend(smoothed_scores)
            anomaly_videos_processed += 1
        
        processed_videos += 1
        total_sample_frames += len(frame_scores)
        
        # print(f"å¤„ç†è§†é¢‘ {video_name_full}: {len(frame_scores)} ä¸ªé‡‡æ ·å¸§ -> {len(full_indices)} ä¸ªå®Œæ•´å¸§")
    
    # è®¡ç®—è§†é¢‘çº§åˆ«ç»Ÿè®¡
    successful_videos = [v for v in video_metrics.values() if v['status'] == 'success']
    if successful_videos:
        video_aurocs = [v['auroc'] for v in successful_videos]
        video_auprs = [v['aupr'] for v in successful_videos]
        
        video_level_stats = {
            'mean_auroc': float(np.mean(video_aurocs)),
            'std_auroc': float(np.std(video_aurocs)),
            'mean_aupr': float(np.mean(video_auprs)),
            'std_aupr': float(np.std(video_auprs)),
            'successful_videos': len(successful_videos),
            'skipped_videos': len([v for v in video_metrics.values() if v['status'] == 'skipped']),
            'error_videos': len([v for v in video_metrics.values() if v['status'] == 'error'])
        }
    else:
        video_level_stats = {
            'mean_auroc': 0.0,
            'std_auroc': 0.0,
            'mean_aupr': 0.0,
            'std_aupr': 0.0,
            'successful_videos': 0,
            'skipped_videos': len([v for v in video_metrics.values() if v['status'] == 'skipped']),
            'error_videos': len([v for v in video_metrics.values() if v['status'] == 'error'])
        }
    
    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    if len(y_true_all) > 0 and len(set(y_true_all)) > 1:
        print(f"y_scores_all: {len(y_scores_all)}")
        try:
            overall_auroc = roc_auc_score(y_true_all, y_scores_all)
            precision, recall, _ = precision_recall_curve(y_true_all, y_scores_all)
            overall_aupr = auc(recall, precision)
            
            # è®¡ç®—åªåŒ…å«å¼‚å¸¸è§†é¢‘çš„æŒ‡æ ‡
            anomaly_only_auroc = 0.0
            anomaly_only_aupr = 0.0
            if len(y_true_anomaly_only) > 0 and len(set(y_true_anomaly_only)) > 1:
                anomaly_only_auroc = roc_auc_score(y_true_anomaly_only, y_scores_anomaly_only)
                precision_anomaly, recall_anomaly, _ = precision_recall_curve(y_true_anomaly_only, y_scores_anomaly_only)
                anomaly_only_aupr = auc(recall_anomaly, precision_anomaly)
            
            print(f"\n" + "="*80)
            print(f"è¯¦ç»†è¯„ä¼°ç»“æœ:")
            print(f"="*80)
            
            # æ˜¾ç¤ºè§†é¢‘çº§åˆ«ç»Ÿè®¡
            print(f"ğŸ“Š è§†é¢‘çº§åˆ«ç»Ÿè®¡:")
            print(f"   æˆåŠŸè®¡ç®—æŒ‡æ ‡çš„è§†é¢‘: {video_level_stats['successful_videos']}")
            print(f"   è·³è¿‡çš„è§†é¢‘ï¼ˆå•ä¸€æ ‡ç­¾ï¼‰: {video_level_stats['skipped_videos']}")
            print(f"   é”™è¯¯çš„è§†é¢‘: {video_level_stats['error_videos']}")
            if video_level_stats['successful_videos'] > 0:
                print(f"   è§†é¢‘å¹³å‡AUROC: {video_level_stats['mean_auroc']:.4f} Â± {video_level_stats['std_auroc']:.4f}")
                print(f"   è§†é¢‘å¹³å‡AUPR: {video_level_stats['mean_aupr']:.4f} Â± {video_level_stats['std_aupr']:.4f}")
            
            print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡:")
            print(f"   å¤„ç†è§†é¢‘æ•°: {processed_videos}/{total_videos}")
            print(f"   å…¶ä¸­å¼‚å¸¸è§†é¢‘æ•°: {anomaly_videos_processed}")
            print(f"   æ­£å¸¸è§†é¢‘æ•°: {processed_videos - anomaly_videos_processed}")
            print(f"   æ€»é‡‡æ ·å¸§æ•°: {total_sample_frames}")
            print(f"   æ€»å®Œæ•´å¸§æ•°: {len(y_true_all)}")
            print(f"   å¼‚å¸¸å¸§æ•°: {int(sum(y_true_all))}")
            print(f"   å¼‚å¸¸å¸§æ¯”ä¾‹: {sum(y_true_all)/len(y_true_all)*100:.2f}%")
            print(f"   å½’ä¸€åŒ–è®¾ç½®: {'å¼€å¯' if normalize else 'å…³é—­'}")
            
            print(f"\nğŸ” å…¨éƒ¨æ•°æ®æ•´ä½“æŒ‡æ ‡:")
            print(f"   æ•´ä½“AUROC (å…¨éƒ¨è§†é¢‘): {overall_auroc:.4f}")
            print(f"   æ•´ä½“AUPR (å…¨éƒ¨è§†é¢‘): {overall_aupr:.4f}")
            
            if len(y_true_anomaly_only) > 0:
                print(f"\nğŸ¯ å¼‚å¸¸è§†é¢‘æ•´ä½“æŒ‡æ ‡:")
                print(f"   å¼‚å¸¸è§†é¢‘å®Œæ•´å¸§æ•°: {len(y_true_anomaly_only)}")
                print(f"   å¼‚å¸¸è§†é¢‘å¼‚å¸¸å¸§æ•°: {int(sum(y_true_anomaly_only))}")
                print(f"   å¼‚å¸¸è§†é¢‘å¼‚å¸¸å¸§æ¯”ä¾‹: {sum(y_true_anomaly_only)/len(y_true_anomaly_only)*100:.2f}%")
                if len(set(y_true_anomaly_only)) > 1:
                    print(f"   æ•´ä½“AUROC (ä»…å¼‚å¸¸è§†é¢‘): {anomaly_only_auroc:.4f}")
                    print(f"   æ•´ä½“AUPR (ä»…å¼‚å¸¸è§†é¢‘): {anomaly_only_aupr:.4f}")
                else:
                    print(f"   å¼‚å¸¸è§†é¢‘æ•°æ®æ ‡ç­¾å•ä¸€ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡")
            else:
                print(f"\nğŸ¯ å¼‚å¸¸è§†é¢‘æ•´ä½“æŒ‡æ ‡:")
                print(f"   æ²¡æœ‰å¤„ç†åˆ°å¼‚å¸¸è§†é¢‘æ•°æ®")
            
            print(f"\nğŸ“‹ å„è§†é¢‘è¯¦ç»†æŒ‡æ ‡:")
            print(f"{'-'*80}")
            print(f"{'è§†é¢‘åç§°':<20} {'AUROC':<8} {'AUPR':<8} {'çŠ¶æ€':<10} {'å¼‚å¸¸å¸§':<8} {'æ€»å¸§æ•°':<8}")
            print(f"{'-'*80}")
            for video_name, metrics in video_metrics.items():
                status_display = {
                    'success': 'âœ…æˆåŠŸ',
                    'skipped': 'âš ï¸è·³è¿‡',
                    'error': 'âŒé”™è¯¯'
                }.get(metrics['status'], metrics['status'])
                
                if metrics['status'] == 'success':
                    print(f"{video_name:<20} {metrics['auroc']:<8.4f} {metrics['aupr']:<8.4f} "
                          f"{status_display:<10} {metrics['anomaly_frames']:<8} {metrics['total_frames']:<8}")
                else:
                    print(f"{video_name:<20} {'N/A':<8} {'N/A':<8} "
                          f"{status_display:<10} {metrics['anomaly_frames']:<8} {metrics['total_frames']:<8}")
            
            print(f"="*80)
            
            # ä¿å­˜è¯„ä¼°ç»“æœ
            evaluation_results = {
                'overall_metrics': {
                    'auroc_all_videos': overall_auroc,
                    'aupr_all_videos': overall_aupr,
                    'auroc_anomaly_only': anomaly_only_auroc,
                    'aupr_anomaly_only': anomaly_only_aupr,
                    'processed_videos': processed_videos,
                    'anomaly_videos_processed': anomaly_videos_processed,
                    'normal_videos_processed': processed_videos - anomaly_videos_processed,
                    'total_videos': total_videos,
                    'total_sample_frames': total_sample_frames,
                    'total_frames': len(y_true_all),
                    'anomaly_frames': int(sum(y_true_all)),
                    'anomaly_ratio': float(sum(y_true_all)/len(y_true_all)),
                    'anomaly_only_frames': len(y_true_anomaly_only),
                    'anomaly_only_anomaly_frames': int(sum(y_true_anomaly_only)) if len(y_true_anomaly_only) > 0 else 0,
                    'normalize_enabled': normalize,
                    'interpolation_method': 'weighted' if use_weighted_interpolation else 'linear'
                },
                'video_level_stats': video_level_stats,
                'individual_video_metrics': video_metrics
            }
            
            results_path = os.path.join(output_dir, 'evaluation_results.json')
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(evaluation_results, f, ensure_ascii=False, indent=4)
            
            print(f"ğŸ“ è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}")
            
            # å¦å¤–ä¿å­˜ä¸€ä¸ªCSVæ ¼å¼çš„è§†é¢‘çº§åˆ«æŒ‡æ ‡è¡¨æ ¼
            csv_path = os.path.join(output_dir, 'video_metrics.csv')
            with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['video_name', 'auroc', 'aupr', 'status', 'total_frames', 'sample_frames', 
                             'anomaly_frames', 'anomaly_ratio', 'anomaly_segments', 'score_min', 
                             'score_max', 'score_mean', 'score_std', 'error_message']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for video_name, metrics in video_metrics.items():
                    row = {
                        'video_name': video_name,
                        'auroc': metrics['auroc'] if metrics['status'] == 'success' else 'N/A',
                        'aupr': metrics['aupr'] if metrics['status'] == 'success' else 'N/A',
                        'status': metrics['status'],
                        'total_frames': metrics['total_frames'],
                        'sample_frames': metrics['sample_frames'],
                        'anomaly_frames': metrics['anomaly_frames'],
                        'anomaly_ratio': f"{metrics['anomaly_ratio']:.4f}",
                        'anomaly_segments': metrics['anomaly_segments'],
                        'score_min': f"{metrics['score_range']['min']:.4f}",
                        'score_max': f"{metrics['score_range']['max']:.4f}",
                        'score_mean': f"{metrics['score_range']['mean']:.4f}",
                        'score_std': f"{metrics['score_range']['std']:.4f}",
                        'error_message': metrics['error_message']
                    }
                    writer.writerow(row)
            
            print(f"ğŸ“Š è§†é¢‘æŒ‡æ ‡CSVè¡¨æ ¼å·²ä¿å­˜: {csv_path}")
            
            return overall_auroc, overall_aupr, anomaly_only_auroc, anomaly_only_aupr
            
        except Exception as e:
            print(f"è®¡ç®—æ•´ä½“æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return 0, 0, 0, 0
    else:
        print("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è¿›è¡Œè¯„ä¼°")
        return 0, 0, 0, 0


def main():
    parser = argparse.ArgumentParser(description="å¼‚å¸¸æ£€æµ‹ç»“æœè¯„ä¼°å’Œå¯è§†åŒ–")
    parser.add_argument("--crad_file", type=str, 
                       default="/root/Ours_in_TAD/module_3/result_VAD_TAD_017_Q10_v1/result_TAD_Q10_V1_4.json",
                       help="CRADç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", type=str, 
                       default="/root/Ours_in_TAD/module_3/result_VAD_TAD_017_Q10_v1/evaluation_results_weighted",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--gt_file", type=str, 
                       default="/root/Ours_in_TAD/TAD_dataset/vals.txt",
                       help="Ground truthæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--normalize", action="store_true", default=False,
                       help="æ˜¯å¦å¯¹å¼‚å¸¸åˆ†æ•°è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼ˆé»˜è®¤ï¼šå¼€å¯ï¼‰")
    parser.add_argument("--no_normalize", dest="normalize", action="store_false",
                       help="å…³é—­å¼‚å¸¸åˆ†æ•°å½’ä¸€åŒ–å¤„ç†")
    parser.add_argument("--use_weighted_interpolation", action="store_true", default=True,
                       help="æ˜¯å¦ä½¿ç”¨æƒé‡è¡¥å…¨æ–¹æ³•ï¼Œé»˜è®¤ä¸ºTrue")
    parser.add_argument("--no_weighted_interpolation", dest="use_weighted_interpolation", action="store_false",
                       help="å…³é—­æƒé‡è¡¥å…¨æ–¹æ³•")
    parser.add_argument("--scores_dir", type=str,
                       default="/root/Ours_in_TAD/module_2/result_sample_TAD",
                       help="æƒé‡åˆ†æ•°æ–‡ä»¶ç›®å½•è·¯å¾„")
    parser.add_argument("--distance_weight_factor", type=float, default=1.0,
                       help="è·ç¦»æƒé‡å› å­ï¼Œé»˜è®¤ä¸º2.0")
    parser.add_argument("--context_weight_factor", type=float, default=2.0,
                       help="contextualæƒé‡å› å­ï¼Œé»˜è®¤ä¸º1.0")
    parser.add_argument("--semantic_weight_factor", type=float, default=0.5,
                       help="semanticæƒé‡å› å­ï¼Œé»˜è®¤ä¸º1.5")
    
    args = parser.parse_args()

    """
    ä½¿ç”¨ç¤ºä¾‹:
    é»˜è®¤æƒ…å†µä¸‹å½’ä¸€åŒ–æ˜¯å¼€å¯çš„ï¼Œæƒé‡è¡¥å…¨æ˜¯å¼€å¯çš„ï¼špython VAD_4_metrics_visual_TAD_v2.py
    è¦å…³é—­å½’ä¸€åŒ–ï¼špython VAD_4_metrics_visual_TAD_v2.py --no_normalize
    è¦å¼€å¯å½’ä¸€åŒ–ï¼špython VAD_4_metrics_visual_TAD_v2.py --normalize
    è¦å…³é—­æƒé‡è¡¥å…¨ï¼ˆä½¿ç”¨çº¿æ€§æ’å€¼ï¼‰ï¼špython VAD_4_metrics_visual_TAD_v2.py --no_weighted_interpolation
    åŒæ—¶è®¾ç½®å¤šä¸ªå‚æ•°ï¼špython VAD_4_metrics_visual_TAD_v2.py --normalize --no_weighted_interpolation
    
    æƒé‡å‚æ•°è°ƒæ•´ç¤ºä¾‹:
    python VAD_4_metrics_visual_TAD_v2.py --distance_weight_factor 3.0 --semantic_weight_factor 2.0
    python VAD_4_metrics_visual_TAD_v2.py --scores_dir /path/to/scores --context_weight_factor 1.5
    """
    
    print("å¼€å§‹åŠ è½½CRADç»“æœ...")
    crad_results = load_crad_results(args.crad_file)
    print(f"åŠ è½½äº† {len(crad_results)} ä¸ªè§†é¢‘çš„ç»“æœ")
    
    print(f"å½’ä¸€åŒ–è®¾ç½®: {'å¼€å¯' if args.normalize else 'å…³é—­'}")
    print(f"è¡¥å…¨æ–¹æ³•: {'æƒé‡è¡¥å…¨' if args.use_weighted_interpolation else 'çº¿æ€§æ’å€¼'}")
    if args.use_weighted_interpolation:
        print(f"æƒé‡å‚æ•°è®¾ç½®:")
        print(f"  - æƒé‡åˆ†æ•°ç›®å½•: {args.scores_dir}")
        print(f"  - è·ç¦»æƒé‡å› å­: {args.distance_weight_factor}")
        print(f"  - Contextualæƒé‡å› å­: {args.context_weight_factor}")
        print(f"  - Semanticæƒé‡å› å­: {args.semantic_weight_factor}")
    print("å¼€å§‹è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    auroc, aupr, anomaly_only_auroc, anomaly_only_aupr = compute_metrics(crad_results, args.gt_file, args.output_dir, args.normalize, args.use_weighted_interpolation, args.scores_dir, args.distance_weight_factor, args.context_weight_factor, args.semantic_weight_factor)
    
    print(f"\næœ€ç»ˆè¯„ä¼°ç»“æœ:")
    print(f"ğŸ“Š å…¨éƒ¨è§†é¢‘æŒ‡æ ‡:")
    print(f"   AUROC (All Videos): {auroc:.4f}")
    print(f"   AUPR (All Videos): {aupr:.4f}")
    print(f"ğŸ¯ å¼‚å¸¸è§†é¢‘æŒ‡æ ‡:")
    print(f"   AUROC (Anomaly Videos Only): {anomaly_only_auroc:.4f}")
    print(f"   AUPR (Anomaly Videos Only): {anomaly_only_aupr:.4f}")


if __name__ == "__main__":
    main()
